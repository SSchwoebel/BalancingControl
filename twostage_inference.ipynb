{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6282599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax.lax import scan, cond\n",
    "from jax import random, jit\n",
    "from functools import partial\n",
    "import numpyro as pyro\n",
    "import numpyro.distributions as dist\n",
    "import itertools\n",
    "import jsonpickle as pickle\n",
    "import jsonpickle.ext.numpy as jsonpickle_numpy\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6305fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5b2982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "\n",
    "    jsonpickle_numpy.register_handlers()\n",
    "\n",
    "    with open(fname, 'r') as infile:\n",
    "        loaded = json.load(infile)\n",
    "\n",
    "    data = pickle.decode(loaded)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e0f8055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_big_trans_matrix(state_trans_matrix, policies):\n",
    "\n",
    "    npi = policies.shape[0]\n",
    "    big_trans_matrix = jnp.stack([jnp.stack([state_trans_matrix[:,:,policies[pi,t]] for pi in range(npi)]) for t in range(T-1)]).transpose((2,3,1,0))\n",
    "    \n",
    "    return big_trans_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31320700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_possible_policies(data, policies):\n",
    "    \n",
    "    npi = policies.shape[0]\n",
    "    all_possible_policies = [[[True]*npi]*T]*trials\n",
    "    \n",
    "    for curr_observed in data:\n",
    "        \n",
    "        curr_obs = curr_observed[\"obs\"]\n",
    "        curr_rew = curr_observed[\"rew\"]\n",
    "        response = curr_observed[\"response\"]\n",
    "        t = curr_observed[\"t\"]\n",
    "        tau = curr_observed[\"tau\"]\n",
    "        \n",
    "        if t == 0:\n",
    "            all_possible_policies[tau][t] = jnp.stack(all_possible_policies[tau][t])\n",
    "        if t>0:# and t < self.T - 1:\n",
    "            possible_policies = policies[:,t-1]==response[t-1]\n",
    "            possible_policies = jnp.logical_and(all_possible_policies[tau][t-1], possible_policies)\n",
    "            all_possible_policies[tau][t] = jnp.stack(possible_policies)\n",
    "            \n",
    "        if t == T-1:\n",
    "            all_possible_policies[tau] = jnp.stack(all_possible_policies[tau])\n",
    "            \n",
    "    return jnp.stack(all_possible_policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e01454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_post_actions_mask(policies, T, na):\n",
    "    \n",
    "    return jnp.stack([jnp.stack([policies[:,t]==a for a in range(na)]) for t in range(T-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d33e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data, T):\n",
    "\n",
    "    shaped_data = []\n",
    "    \n",
    "    for curr_observed in data:\n",
    "\n",
    "        curr_obs = curr_observed[\"obs\"]\n",
    "        curr_rew = curr_observed[\"rew\"]\n",
    "        response = curr_observed[\"response\"]\n",
    "        t = curr_observed[\"t\"]\n",
    "        tau = curr_observed[\"tau\"]\n",
    "\n",
    "        shaped_data.append(jnp.stack(\n",
    "            [jnp.stack(curr_obs), \n",
    "             jnp.stack(curr_rew), \n",
    "             jnp.stack(response), \n",
    "             jnp.stack([tau]*T), \n",
    "             jnp.stack([t]*T)]))\n",
    "        \n",
    "    return jnp.stack(shaped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5544095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "trials =  201#number of trials\n",
    "T = 3 #number of time steps in each trial\n",
    "nb = 4\n",
    "ns = 3+nb #number of states\n",
    "no = ns #number of observations\n",
    "na = 2 #number of actions\n",
    "npi = na**(T-1)\n",
    "nr = 2\n",
    "\n",
    "#generating probability of observations in each state\n",
    "A = jnp.eye(no)#.to(device)\n",
    "obs_matrix = A\n",
    "\n",
    "#state transition generative probability (matrix)\n",
    "B = jnp.zeros((ns, ns, na))\n",
    "b1 = 0.7\n",
    "nb1 = 1.-b1\n",
    "b2 = 0.7\n",
    "nb2 = 1.-b2\n",
    "\n",
    "state_trans_matrix = jnp.array([[[  0,  0,  0,  0,  0,  0,  0,],\n",
    "                     [ b1,  0,  0,  0,  0,  0,  0,],\n",
    "                     [nb1,  0,  0,  0,  0,  0,  0,],\n",
    "                     [  0,  1,  0,  1,  0,  0,  0,],\n",
    "                     [  0,  0,  1,  0,  1,  0,  0,],\n",
    "                     [  0,  0,  0,  0,  0,  1,  0,],\n",
    "                     [  0,  0,  0,  0,  0,  0,  1,],],\n",
    "\n",
    "                    [[  0,  0,  0,  0,  0,  0,  0,],\n",
    "                     [nb2,  0,  0,  0,  0,  0,  0,],\n",
    "                     [ b2,  0,  0,  0,  0,  0,  0,],\n",
    "                     [  0,  0,  0,  1,  0,  0,  0,],\n",
    "                     [  0,  0,  0,  0,  1,  0,  0,],\n",
    "                     [  0,  1,  0,  0,  0,  1,  0,],\n",
    "                     [  0,  0,  1,  0,  0,  0,  1,],]]).transpose((1,2,0))\n",
    "\n",
    "\n",
    "u = 0.999\n",
    "utility = jnp.array([1-u, u])\n",
    "\n",
    "preference = utility\n",
    "\n",
    "fix_rew_counts = jnp.array([[100]*3, [1]*3])[:,:,None]\n",
    "\n",
    "init_rew_counts = jnp.ones((nr, ns-3, 1))\n",
    "\n",
    "policies = jnp.array(list(itertools.product(list(range(na)), repeat=T-1)))\n",
    "\n",
    "big_trans_matrix = calc_big_trans_matrix(state_trans_matrix, policies)\n",
    "\n",
    "state_prior = jnp.eye(ns)[0]\n",
    "\n",
    "npart = 1\n",
    "npi = policies.shape[0]\n",
    "prior_states = jnp.repeat(jnp.repeat(state_prior[:,None], npi, axis=1)[:,:,None], npart, axis=1) #+ 1e-20\n",
    "bwd_init = jnp.repeat(jnp.repeat((jnp.ones_like(state_prior)/prior_states.shape[0])[:,None], npi, axis=1)[:,:,None], npart, axis=1)\n",
    "print(bwd_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2568e607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "lp = 0.3\n",
    "lr = 0.3\n",
    "dt = 5.\n",
    "tend = 1./1000\n",
    "\n",
    "folder = \"data\"\n",
    "\n",
    "run_name = \"twostage_results\"+str(i)+\"_pl\"+str(lp)+\"_rl\"+str(lr)+\"_dt\"+str(dt)+\"_tend\"+str(int(1./tend))+\".json\"\n",
    "fname = os.path.join(folder, run_name)\n",
    "\n",
    "data = load_data(fname=fname)\n",
    "\n",
    "all_possible_policies = calc_possible_policies(data, policies)\n",
    "print(all_possible_policies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3084c288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(603, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "nicely_shaped_data = transform_data(data, T)\n",
    "print(nicely_shaped_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62c12581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True False False]\n",
      " [False False  True  True]]\n"
     ]
    }
   ],
   "source": [
    "post_actions_mask = calc_post_actions_mask(policies, T, na)\n",
    "print(post_actions_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75461eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bayesian_habit_model():\n",
    "    \n",
    "    # generative model of behavior with Normally distributed params (within subject!!)\n",
    "\n",
    "    # tell pyro about prior over parameters: alpha and beta of lambda which is between 0 and 1\n",
    "    # alpha = beta = 1 equals uniform prior\n",
    "    alpha_lambda_pi = jnp.ones(1)#.to(device)\n",
    "    beta_lambda_pi = jnp.ones(1)#.to(device)\n",
    "    # sample initial vaue of parameter from Beta distribution\n",
    "    lambda_pi = pyro.sample('lambda_pi', dist.Beta(alpha_lambda_pi, beta_lambda_pi))#.to(device)\n",
    "\n",
    "    # tell pyro about prior over parameters: alpha and beta of lambda which is between 0 and 1\n",
    "    # alpha = beta = 1 equals uniform prior\n",
    "    alpha_lambda_r = jnp.ones(1)#.to(device)\n",
    "    beta_lambda_r = jnp.ones(1)#.to(device)\n",
    "    # sample initial vaue of parameter from Beta distribution\n",
    "    lambda_r = pyro.sample('lambda_r', dist.Beta(alpha_lambda_r, beta_lambda_r))#.to(device)\n",
    "\n",
    "    # tell pyro about prior over parameters: alpha and beta of h which is between 0 and 1\n",
    "    # alpha = beta = 1 equals uniform prior\n",
    "    alpha_h = jnp.ones(1)#.to(device)\n",
    "    beta_h = jnp.ones(1)#.to(device)\n",
    "    # sample initial vaue of parameter from Beta distribution\n",
    "    h = pyro.sample('h', dist.Beta(alpha_h, beta_h))#.to(device)\n",
    "    alpha = 1./h\n",
    "    \n",
    "    init_pol_counts = jnp.zeros((npi, 1)) + alpha\n",
    "\n",
    "    # tell pyro about prior over parameters: decision temperature\n",
    "    # uniform between 0 and 20??\n",
    "    concentration_dec_temp = jnp.array(1.)#.to(device)\n",
    "    rate_dec_temp = jnp.array(0.5)#.to(device)\n",
    "    # sample initial vaue of parameter from normal distribution\n",
    "    dec_temp = pyro.sample('dec_temp', dist.Gamma(concentration_dec_temp, rate_dec_temp))#.to(device)\n",
    "    \n",
    "    \n",
    "    @jit\n",
    "    def step(carry, curr_observed):\n",
    "        \n",
    "        rew_counts, pol_counts = carry\n",
    "        \n",
    "        curr_obs, curr_rew, curr_response, curr_tau, curr_t = curr_observed\n",
    "        \n",
    "        #curr_obs = curr_observed[\"obs\"]\n",
    "        #curr_rew = curr_observed[\"rew\"]\n",
    "        t = curr_t[0]\n",
    "        tau = curr_tau[0]\n",
    "        \n",
    "        possible_policies = all_possible_policies[tau,t]\n",
    "        \n",
    "        total_counts = jnp.concatenate([fix_rew_counts, rew_counts], axis=1)\n",
    "        rew_matrix = total_counts / total_counts.sum(axis=0)\n",
    "        prior_policies = pol_counts / pol_counts.sum(axis=0)\n",
    "    \n",
    "        @jit\n",
    "        def make_rew_messages(rew_matrix, curr_rew):\n",
    "\n",
    "            def future_func(rew):\n",
    "                return jnp.einsum('r,rsn->sn', preference, rew_matrix)\n",
    "                \n",
    "            def past_func(rew):\n",
    "                return rew_matrix[rew]\n",
    "            \n",
    "            rew_messages = []\n",
    "            for i, rew in enumerate(curr_rew):\n",
    "                rew_messages.append(cond(rew != -1, past_func, future_func, rew))\n",
    "                #if rew != -1:\n",
    "                #    rew_messages.append(rew_matrix[rew])\n",
    "                #else:\n",
    "                #    rew_messages.append(jnp.einsum('r,rsn->sn', preference, rew_matrix))\n",
    "\n",
    "            return jnp.stack(rew_messages).transpose((1,0,2))\n",
    "\n",
    "        @jit\n",
    "        def make_obs_messages(curr_obs):\n",
    "\n",
    "            def future_func(obs):\n",
    "                return jnp.dot(jnp.ones(no)/no, obs_matrix)\n",
    "                \n",
    "            def past_func(obs):\n",
    "                return obs_matrix[obs]\n",
    "\n",
    "            obs_messages = []\n",
    "            for i, obs in enumerate(curr_obs):\n",
    "                obs_messages.append(cond(obs != -1, past_func, future_func, obs))\n",
    "                #if obs != -1:\n",
    "                #    obs_messages.append(obs_matrix[obs])\n",
    "                #else:\n",
    "                #    no = obs_matrix.shape[0]\n",
    "                #    obs_messages.append(jnp.dot(jnp.ones(no)/no, obs_matrix))\n",
    "\n",
    "            return jnp.stack(obs_messages).transpose((1,0))\n",
    "            i += 1\n",
    "\n",
    "        @jit    \n",
    "        def scan_fwd_messages(carry, input_message):\n",
    "\n",
    "            i, old_message = carry\n",
    "            rew_message, obs_message = input_message\n",
    "            tmp_message = jnp.einsum('hpn,shp,hn,hn->spn', old_message, big_trans_matrix[...,i], obs_message, rew_message)\n",
    "\n",
    "            norm = tmp_message.sum(axis=0)\n",
    "            message = jnp.where(norm > 0, tmp_message/norm[None,...], tmp_message)\n",
    "            #norms = jnp.where(possible_policies[:,None], norm, 0)\n",
    "            i += 1\n",
    "\n",
    "            return (i, message), (message, norm)\n",
    "\n",
    "        @jit\n",
    "        def make_fwd_messages(rew_messages, obs_messages):\n",
    "\n",
    "            input_messages = jnp.stack([jnp.stack([rew_messages[:,i], obs_messages[:,i][:,None]]) for i in range(T-1)])\n",
    "            init = (0, prior_states)\n",
    "\n",
    "            carry, fwd = scan(scan_fwd_messages, init, input_messages)\n",
    "            fwd_messages, fwd_norms = fwd\n",
    "            fwd_messages = jnp.concatenate([init[1][None,...], fwd_messages], axis=0).transpose((1,0,2,3))\n",
    "\n",
    "            return fwd_messages, fwd_norms\n",
    "\n",
    "        @jit    \n",
    "        def scan_bwd_messages(carry, input_message):\n",
    "\n",
    "            i, old_message = carry\n",
    "            rew_message, obs_message = input_message\n",
    "\n",
    "            #print(\"old\", old_message)\n",
    "            tmp_message = jnp.einsum('hpn,shp,hn,hn->spn', old_message, big_trans_matrix[...,i].transpose((1,0,2)), obs_message, rew_message)\n",
    "            # print(tmp_message)\n",
    "\n",
    "            norm = tmp_message.sum(axis=0)\n",
    "            message = tmp_message#jnp.where(norm > 0, tmp_message/norm[None,...], tmp_message)\n",
    "\n",
    "            return (i, message), (message, norm)\n",
    "\n",
    "        @jit\n",
    "        def make_bwd_messages(rew_messages, obs_messages):\n",
    "\n",
    "            input_messages = jnp.stack([jnp.stack([rew_messages[:,i+1], obs_messages[:,i+1][:,None]]) for i in range(T-1)])\n",
    "            init = (0, bwd_init)\n",
    "            carry = init\n",
    "            carry, bwd = scan(scan_bwd_messages, init, input_messages, reverse=True)\n",
    "            bwd_messages, bwd_norms = bwd\n",
    "            bwd_messages = jnp.concatenate([bwd_messages, init[1][None,...]], axis=0).transpose((1,0,2,3))\n",
    "\n",
    "            return bwd_messages\n",
    "\n",
    "        @jit    \n",
    "        def eval_posterior_policies(fwd_norms, prior_policies):\n",
    "\n",
    "            likelihood = (fwd_norms).prod(axis=0)#+1e-10\n",
    "            norm = likelihood.sum(axis=0)\n",
    "            post = jnp.power(likelihood/norm, dec_temp[None,:]) * prior_policies\n",
    "            posterior_policies = post / post.sum(axis=0)\n",
    "\n",
    "            return posterior_policies\n",
    "\n",
    "        def post_actions_from_policies(posterior_policies, t):\n",
    "\n",
    "            post_actions = jnp.stack([posterior_policies[policies[:,t]==a].sum() for a in range(na)])\n",
    "\n",
    "            return post_actions\n",
    "\n",
    "        @jit        \n",
    "        def contract_posterior_policies(posterior_policies, a, t):\n",
    "\n",
    "            return posterior_policies[policies[t]==a].sum()\n",
    "\n",
    "        @jit    \n",
    "        def update_rew_counts(prev_rew_counts, curr_rew, post_states, t=-1):\n",
    "\n",
    "            #note to self: try implemementing with binary mask multiplication instead of separated matrices\n",
    "            # maybe using jnp.where ?\n",
    "            no = prev_rew_counts.shape[0]\n",
    "            if t == -1:\n",
    "                for i, rew in enumerate(curr_rew):\n",
    "                    if rew != -1:\n",
    "                        rew_counts = (1-lambda_r)[None,None,...]*prev_rew_counts + lambda_r[None,None,...] \\\n",
    "                            + jnp.eye(no)[rew][:,None,...]*post_states[-prev_rew_counts.shape[1]:,i,...][None,:,...]\n",
    "                        prev_rew_counts = rew_counts\n",
    "            else:\n",
    "                rew = curr_rew[t]\n",
    "                rew_counts = (1-lambda_r)[None,None,...]*prev_rew_counts + lambda_r[None,None,...] \\\n",
    "                            + jnp.eye(no)[rew][:,None,None]*post_states[-prev_rew_counts.shape[1]:,t,...][None,:,:]\n",
    "\n",
    "            return rew_counts\n",
    "\n",
    "        @jit\n",
    "        def update_pol_counts(prev_pol_counts, posterior_policies):\n",
    "\n",
    "            pol_counts = (1-lambda_pi)[None,...]*prev_pol_counts + (lambda_pi)[None,...]*alpha + posterior_policies\n",
    "\n",
    "            return pol_counts\n",
    "        \n",
    "        rew_messages = make_rew_messages(rew_matrix, curr_rew)\n",
    "        obs_messages = make_obs_messages(curr_obs)\n",
    "        fwd_messages, fwd_norms = make_fwd_messages(rew_messages, obs_messages)\n",
    "        bwd_messages = make_bwd_messages(rew_messages, obs_messages)\n",
    "        \n",
    "        posterior_states = fwd_messages*bwd_messages*obs_messages[...,None,None]*rew_messages[...,None]\n",
    "        norm = posterior_states.sum(axis=0)\n",
    "        \n",
    "        posterior_states = jnp.where(norm[None,...] > 0, posterior_states/norm[None,...],  posterior_states)\n",
    "        fwd_norms = jnp.concatenate([fwd_norms, norm[-1][None,:]], axis=0)\n",
    "        fwd_norms = jnp.where(possible_policies[:,None], fwd_norms, 0)\n",
    "        \n",
    "        posterior_policies = eval_posterior_policies(fwd_norms, prior_policies)\n",
    "        \n",
    "        marginal_posterior_states = jnp.einsum('stpn,pn->stn', posterior_states, posterior_policies)\n",
    "        \n",
    "        posterior_actions = post_actions_from_policies(posterior_policies, t)\n",
    "        \n",
    "        if t==self.T-1:\n",
    "            rew_counts = update_rew_counts(rew_counts, curr_rew, marginal_posterior_states, t=t)\n",
    "            pol_counts = update_pol_counts(pol_counts, posterior_policies)\n",
    "            \n",
    "        curr_response = curr_observed[\"response\"][t]\n",
    "        pyro.sample('res_{}_{}'.format(tau, t), dist.Categorical(posterior_actions.T), obs=curr_response)\n",
    "        \n",
    "        return (rew_counts, pol_counts), posterior_actions\n",
    "    \n",
    "    \n",
    "    carry = (init_rew_counts, init_pol_counts)\n",
    "    \n",
    "    _, posterior_actions = scan(step, carry, nicely_shaped_data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e9d4a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide():\n",
    "    # approximate posterior. assume MF: each param has his own univariate Normal.\n",
    "\n",
    "    # tell pyro about posterior over parameters: alpha and beta of lambda which is between 0 and 1\n",
    "    alpha_lambda_pi = pyro.param(\"alpha_lambda_pi\", jnp.ones(1), constraint=pyro.distributions.constraints.positive)#.to(device)#greater_than_eq(1.))\n",
    "    beta_lambda_pi = pyro.param(\"beta_lambda_pi\", jnp.ones(1), constraint=pyro.distributions.constraints.positive)#.to(device)#greater_than_eq(1.))\n",
    "    # sample vaue of parameter from Beta distribution\n",
    "    # print()\n",
    "    # print(alpha_lamb_pi, beta_lamb_pi)\n",
    "    lambda_pi = pyro.sample('lambda_pi', dist.Beta(alpha_lambda_pi, beta_lambda_pi))#.to(device)\n",
    "\n",
    "    # tell pyro about posterior over parameters: alpha and beta of lambda which is between 0 and 1\n",
    "    alpha_lambda_r = pyro.param(\"alpha_lambda_r\", jnp.ones(1), constraint=pyro.distributions.constraints.positive)#.to(device)#greater_than_eq(1.))\n",
    "    beta_lambda_r = pyro.param(\"beta_lambda_r\", jnp.ones(1), constraint=pyro.distributions.constraints.positive)#.to(device)#greater_than_eq(1.))\n",
    "    # sample initial vaue of parameter from Beta distribution\n",
    "    lambda_r = pyro.sample('lambda_r', dist.Beta(alpha_lambda_r, beta_lambda_r))#.to(device)\n",
    "\n",
    "    # tell pyro about posterior over parameters: alpha and beta of lambda which is between 0 and 1\n",
    "    alpha_h = pyro.param(\"alpha_h\", jnp.ones(1), constraint=pyro.distributions.constraints.positive)#.to(device)#greater_than_eq(1.))\n",
    "    beta_h = pyro.param(\"beta_h\", jnp.ones(1), constraint=pyro.distributions.constraints.positive)#.to(device)#greater_than_eq(1.))\n",
    "    # sample initial vaue of parameter from Beta distribution\n",
    "    h = pyro.sample('h', dist.Beta(alpha_h, beta_h))#.to(device)\n",
    "\n",
    "    # tell pyro about posterior over parameters: mean and std of the decision temperature\n",
    "    concentration_dec_temp = pyro.param(\"concentration_dec_temp\", jnp.ones(1)*3., constraint=pyro.distributions.constraints.positive)#.to(device)#interval(0., 7.))\n",
    "    rate_dec_temp = pyro.param(\"rate_dec_temp\", jnp.ones(1), constraint=pyro.distributions.constraints.positive)#.to(device)\n",
    "    # sample initial vaue of parameter from normal distribution\n",
    "    dec_temp = pyro.sample('dec_temp', dist.Gamma(concentration_dec_temp, rate_dec_temp))#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4510bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_posterior(iter_steps=1000,\n",
    "                    #num_particles=10,\n",
    "                    optim_kwargs={'lr': .01}):\n",
    "    \"\"\"Perform SVI over free model parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    #pyro.clear_param_store()\n",
    "\n",
    "    svi = pyro.infer.SVI(model=Bayesian_habit_model,\n",
    "              guide=guide,\n",
    "              optim=pyro.optim.Adam(step_size=0.01),# from numpyro documentation #optim_kwargs\n",
    "              loss=pyro.infer.Trace_ELBO(num_particles=2))#num_particles=num_particles\n",
    "    #                          #set below to true once code is vectorized\n",
    "    #                          vectorize_particles=True))\n",
    "\n",
    "    rng_key = random.PRNGKey(100)\n",
    "    loss = []\n",
    "    svi_result = svi.run(rng_key, iter_steps, stable_update=True)\n",
    "    self.params = svi_result.params\n",
    "    self.loss = svi_result.losses\n",
    "    print(svi_result)\n",
    "    # pbar = tqdm(range(iter_steps), position=0)\n",
    "    # for step in pbar:\n",
    "    #     loss.append(jnp.array(svi.step()))#.to(device))\n",
    "    #     pbar.set_description(\"Mean ELBO %6.2f\" % jnp.array(loss[-20:]).mean())\n",
    "    #     if jnp.isnan(loss[-1]):\n",
    "    #         break\n",
    "\n",
    "    # self.loss = [l.cpu() for l in loss]\n",
    "\n",
    "    # final_elbo = -pyro.infer.Trace_ELBO(num_particles=1000).loss(rng_key, self.params, self.model, self.guide)\n",
    "    # print(final_elbo)\n",
    "\n",
    "    # with pyro.handlers.seed(rng_seed=0):\n",
    "    #     trace = pyro.handlers.trace(self.model).get_trace()\n",
    "    # print(pyro.util.format_shapes(trace))\n",
    "\n",
    "    # alpha_lamb_pi = self.params(\"alpha_lamb_pi\")#.data.numpy()\n",
    "    # beta_lamb_pi = self.params(\"beta_lamb_pi\")#.data.numpy()\n",
    "    # alpha_lamb_r = self.params(\"alpha_lamb_r\")#.data.numpy()\n",
    "    # beta_lamb_r = self.params(\"beta_lamb_r\")#.data.numpy()\n",
    "    # alpha_h = self.params(\"alpha_lamb_r\")#.data.numpy()\n",
    "    # beta_h = self.params(\"beta_lamb_r\")#.data.numpy()\n",
    "    # concentration_dec_temp = self.params(\"concentration_dec_temp\")#.data.numpy()\n",
    "    # rate_dec_temp = self.params(\"rate_dec_temp\")#.data.numpy()\n",
    "\n",
    "    param_dict = self.params #{\"alpha_lamb_pi\": alpha_lamb_pi, \"beta_lamb_pi\": beta_lamb_pi,\n",
    "                  #\"alpha_lamb_r\": alpha_lamb_r, \"beta_lamb_r\": beta_lamb_r,\n",
    "                  #\"alpha_h\": alpha_h, \"beta_h\": beta_h,\n",
    "                  #\"concentration_dec_temp\": concentration_dec_temp, \"rate_dec_temp\": rate_dec_temp}\n",
    "    print(param_dict)\n",
    "\n",
    "    return self.loss, param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97e6e6a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NonConcreteBooleanIndexError",
     "evalue": "Array boolean indices must be concrete; got ShapedArray(bool[4])\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.NonConcreteBooleanIndexError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNonConcreteBooleanIndexError\u001b[0m              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minfer_posterior\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36minfer_posterior\u001b[0;34m(iter_steps, optim_kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m rng_key \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 18\u001b[0m svi_result \u001b[38;5;241m=\u001b[39m \u001b[43msvi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstable_update\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m svi_result\u001b[38;5;241m.\u001b[39mparams\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m svi_result\u001b[38;5;241m.\u001b[39mlosses\n",
      "File \u001b[0;32m~/anaconda3/envs/numpyro/lib/python3.9/site-packages/numpyro/infer/svi.py:342\u001b[0m, in \u001b[0;36mSVI.run\u001b[0;34m(self, rng_key, num_steps, progress_bar, stable_update, init_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m svi_state, loss\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 342\u001b[0m     svi_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     svi_state \u001b[38;5;241m=\u001b[39m init_state\n",
      "File \u001b[0;32m~/anaconda3/envs/numpyro/lib/python3.9/site-packages/numpyro/infer/svi.py:181\u001b[0m, in \u001b[0;36mSVI.init\u001b[0;34m(self, rng_key, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m guide_init \u001b[38;5;241m=\u001b[39m seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mguide, guide_seed)\n\u001b[1;32m    180\u001b[0m guide_trace \u001b[38;5;241m=\u001b[39m trace(guide_init)\u001b[38;5;241m.\u001b[39mget_trace(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_kwargs)\n\u001b[0;32m--> 181\u001b[0m model_trace \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide_trace\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatic_kwargs\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    185\u001b[0m inv_transforms \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/numpyro/lib/python3.9/site-packages/numpyro/handlers.py:171\u001b[0m, in \u001b[0;36mtrace.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    Run the wrapped callable and return the recorded trace.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m    :return: `OrderedDict` containing the execution trace.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace\n",
      "File \u001b[0;32m~/anaconda3/envs/numpyro/lib/python3.9/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/numpyro/lib/python3.9/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/numpyro/lib/python3.9/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mBayesian_habit_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (rew_counts, pol_counts), posterior_actions\n\u001b[1;32m    223\u001b[0m carry \u001b[38;5;241m=\u001b[39m (init_rew_counts, init_pol_counts)\n\u001b[0;32m--> 225\u001b[0m _, posterior_actions \u001b[38;5;241m=\u001b[39m \u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcarry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnicely_shaped_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 20 frame]\u001b[0m\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mBayesian_habit_model.<locals>.step\u001b[0;34m(carry, curr_observed)\u001b[0m\n\u001b[1;32m    207\u001b[0m posterior_policies \u001b[38;5;241m=\u001b[39m eval_posterior_policies(fwd_norms, prior_policies)\n\u001b[1;32m    209\u001b[0m marginal_posterior_states \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstpn,pn->stn\u001b[39m\u001b[38;5;124m'\u001b[39m, posterior_states, posterior_policies)\n\u001b[0;32m--> 211\u001b[0m posterior_actions \u001b[38;5;241m=\u001b[39m \u001b[43mpost_actions_from_policies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposterior_policies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    214\u001b[0m     rew_counts \u001b[38;5;241m=\u001b[39m update_rew_counts(rew_counts, curr_rew, marginal_posterior_states, t\u001b[38;5;241m=\u001b[39mt)\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mBayesian_habit_model.<locals>.step.<locals>.post_actions_from_policies\u001b[0;34m(posterior_policies, t)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost_actions_from_policies\u001b[39m(posterior_policies, t):\n\u001b[0;32m--> 160\u001b[0m     post_actions \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mstack([posterior_policies[policies[:,t]\u001b[38;5;241m==\u001b[39ma]\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(na)])\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m post_actions\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost_actions_from_policies\u001b[39m(posterior_policies, t):\n\u001b[0;32m--> 160\u001b[0m     post_actions \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mstack([\u001b[43mposterior_policies\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpolicies\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(na)])\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m post_actions\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/numpyro/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:4251\u001b[0m, in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   4245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_rewriting_take\u001b[39m(arr, idx, indices_are_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, unique_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   4246\u001b[0m                     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   4247\u001b[0m   \u001b[38;5;66;03m# Computes arr[idx].\u001b[39;00m\n\u001b[1;32m   4248\u001b[0m   \u001b[38;5;66;03m# All supported cases of indexing can be implemented as an XLA gather,\u001b[39;00m\n\u001b[1;32m   4249\u001b[0m   \u001b[38;5;66;03m# followed by an optional reverse and broadcast_in_dim.\u001b[39;00m\n\u001b[1;32m   4250\u001b[0m   arr \u001b[38;5;241m=\u001b[39m asarray(arr)\n\u001b[0;32m-> 4251\u001b[0m   treedef, static_idx, dynamic_idx \u001b[38;5;241m=\u001b[39m \u001b[43m_split_index_for_jit\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4252\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   4253\u001b[0m                  unique_indices, mode, fill_value)\n",
      "File \u001b[0;32m~/anaconda3/envs/numpyro/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:4330\u001b[0m, in \u001b[0;36m_split_index_for_jit\u001b[0;34m(idx, shape)\u001b[0m\n\u001b[1;32m   4326\u001b[0m idx \u001b[38;5;241m=\u001b[39m _eliminate_deprecated_list_indexing(idx)\n\u001b[1;32m   4328\u001b[0m \u001b[38;5;66;03m# Expand any (concrete) boolean indices. We can then use advanced integer\u001b[39;00m\n\u001b[1;32m   4329\u001b[0m \u001b[38;5;66;03m# indexing logic to handle them.\u001b[39;00m\n\u001b[0;32m-> 4330\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[43m_expand_bool_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4332\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(idx)\n\u001b[1;32m   4333\u001b[0m dynamic \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(leaves)\n",
      "File \u001b[0;32m~/anaconda3/envs/numpyro/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:4634\u001b[0m, in \u001b[0;36m_expand_bool_indices\u001b[0;34m(idx, shape)\u001b[0m\n\u001b[1;32m   4630\u001b[0m   abstract_i \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mget_aval(i)\n\u001b[1;32m   4632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(abstract_i) \u001b[38;5;129;01mis\u001b[39;00m ConcreteArray:\n\u001b[1;32m   4633\u001b[0m   \u001b[38;5;66;03m# TODO(mattjj): improve this error by tracking _why_ the indices are not concrete\u001b[39;00m\n\u001b[0;32m-> 4634\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNonConcreteBooleanIndexError(abstract_i)\n\u001b[1;32m   4635\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _ndim(i) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   4636\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJAX arrays do not support boolean scalar indices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNonConcreteBooleanIndexError\u001b[0m: Array boolean indices must be concrete; got ShapedArray(bool[4])\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.NonConcreteBooleanIndexError"
     ]
    }
   ],
   "source": [
    "infer_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b69a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b257cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1700c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
